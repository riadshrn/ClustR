# ClustR  
### Clustering de Variables : K-means â€“ Qualitatif â€“ Deep Learning  
**Package R + Application Shiny**

---

## ğŸ“Œ PrÃ©sentation

**ClustR** est un package R dÃ©diÃ© au **clustering de variables**, permettant de regrouper des variables similaires pour :

- rÃ©duire la dimension,  
- crÃ©er des variables synthÃ©tiques,  
- amÃ©liorer lâ€™interprÃ©tation,  
- faciliter les modÃ¨les prÃ©dictifs.

Il intÃ¨gre **trois algorithmes complÃ©mentaires** :

1. **ClustKMeansVar** â€” PCA + K-means rÃ©allocatif  
2. **ClustQualiVarclus** â€” MCA + rapport de corrÃ©lation Î·Â²  
3. **ClustDeepVar** â€” Autoencodeur + clustering dans lâ€™espace latent  

---

# ğŸš€ 1. ClustKMeansVar (K-means rÃ©allocatif)

MÃ©thode inspirÃ©e de Vigneau & Qannari (2003).

## ğŸ”¹ Principe gÃ©nÃ©ral  
Les variables sont regroupÃ©es selon leur corrÃ©lation avec la **synthetic variable** (PC1) du cluster.

Pour chaque cluster \(C_g\), la synthetic variable est :

<p align="center">
  <img src="images/formulas/1.png" width="210">
</p>

avec :

<p align="center">
  <img src="images/formulas/2.png" width="260">
</p>

oÃ¹ :  

<p align="center">
  <img src="images/formulas/3.png" width="230">
</p>

## ğŸ”¹ Distance variableâ€“cluster  

<p align="center">
  <img src="images/formulas/4.png" width="280">
</p>

La variable \(X_j\) est affectÃ©e au cluster minimisant \(d(j,g)\).

## ğŸ”¹ CritÃ¨re global optimisÃ©  

<p align="center">
  <img src="images/formulas/5.png" width="180">
</p>

oÃ¹ :

- \(W\) = inertie intra-cluster  
- \(B\) = inertie inter-clusters  

ğŸ’¡ **Plus Q est proche de 1, meilleure est la partition.**

## ğŸ”¹ Algorithme complet  
1. Standardiser les variables  
2. Initialiser une partition  
3. Calculer PC1 de chaque cluster  
4. RÃ©affecter chaque variable au cluster optimisant \(d(j,g)\)  
5. Mettre Ã  jour Q  
6. RÃ©pÃ©ter jusquâ€™Ã  convergence  

---

# ğŸš€ 2. ClustQualiVarclus (Clustering qualitatif par MCA + Î·Â²)

MÃ©thode dÃ©diÃ©e aux variables catÃ©gorielles basÃ©e sur lâ€™ACM.

## ğŸ”¹ Ã‰tape 1 â€” Encodage disjonctif complet  

<p align="center">
  <img src="images/formulas/6.png" width="260">
</p>

## ğŸ”¹ Ã‰tape 2 â€” MCA par cluster  
On rÃ©alise une analyse des correspondances multiples sur les modalitÃ©s du cluster.

Lâ€™axe principal obtenu est \(Y_g\).

## ğŸ”¹ Ã‰tape 3 â€” Rapport de corrÃ©lation Î·Â²  

<p align="center">
  <img src="images/formulas/7.png" width="360">
</p>

**Affectation :**

<p align="center">
  <img src="images/formulas/8.png" width="350">
</p>

## ğŸ”¹ Algorithme complet  
1. Partition initiale des variables  
2. MCA pour chaque cluster  
3. Calcul de \(\eta^2(V,Y_g)\) pour chaque variable  
4. RÃ©affectation selon lâ€™Î·Â² maximal  
5. RÃ©pÃ©ter jusquâ€™Ã  convergence  

## ğŸ”¹ Atouts  
- IdÃ©al pour variables nominales / ordinales  
- BasÃ© sur la gÃ©omÃ©trie du Ï‡Â²  
- InterprÃ©tation claire via lâ€™ACM  

---

# ğŸš€ 3. ClustDeepVar (Autoencodeur + clustering latent)

Algorithme deep learning pour capturer les **relations non linÃ©aires** entre variables.

## ğŸ”¹ Ã‰tape 1 â€” Standardisation  

<p align="center">
  <img src="images/formulas/9.png" width="240">
</p>

## ğŸ”¹ Ã‰tape 2 â€” Transposition  

<p align="center">
  <img src="images/formulas/10.png" width="240">
</p>

## ğŸ”¹ Ã‰tape 3 â€” Encodeur (embeddings)  

<p align="center">
  <img src="images/formulas/11.png" width="260">
</p>

Chaque variable est reprÃ©sentÃ©e par un vecteur latent \(z_j \in \mathbb{R}^d\).

## ğŸ”¹ Ã‰tape 4 â€” Reconstruction  

<p align="center">
  <img src="images/formulas/12.png" width="260">
</p>

## ğŸ”¹ Projection de variables illustratives  

<p align="center">
  <img src="images/formulas/13.png" width="360">
</p>

## ğŸ”¹ Ã‰tape 5 â€” Clustering des embeddings  

<p align="center">
  <img src="images/formulas/14.png" width="260">
</p>

## ğŸ”¹ Soft clustering  

<p align="center">
  <img src="images/formulas/15.png" width="380">
</p>

## ğŸ”¹ Projection de variables illustratives  

<p align="center">
  <img src="images/formulas/16.png" width="360">
</p>

---

# ğŸ“Š Fonctions principales de lâ€™application Shiny

### âœ” Chargement de donnÃ©es  
- Jeux intÃ©grÃ©s  
- Upload CSV / TSV / XLSX  
- DÃ©tection automatique des types et NA  

### âœ” SÃ©lection des variables  
- Actives vs illustratives  
- DÃ©tection automatique des variables redondantes  
- Matrice de corrÃ©lation  

### âœ” Choix de lâ€™algorithme  
- DÃ©tection automatique selon le type de donnÃ©es  
- RÃ©glages :  
  - `n_clusters`  
  - `latent_dim`, `epochs`, `dropout` (deep)  

### âœ” Visualisations  
- PCA (KMeans)  
- MCA (Quali)  
- Embeddings 2D/3D (Deep)  
- Heatmaps, distances inter-clusters  
- Î·Â², inerties, silhouette  

### âœ” Nouvelles variables  
- NumÃ©riques : somme / moyenne / ratio / produit / max/min  
- Qualitatives : combinaison, ifelse factor, quantiles  
- Projection dans PCA, MCA ou latent space  
- Soft membership complet  

---

# ğŸ‘¥ Auteurs

- **Riad SAHRANE**  
- **Aya MECHERI**  
- **Thibaud LECOMTE**  
Encadrant : **Ricco Rakotomalala**

---

# ğŸ Statut du projet

- âœ” Package R complet  
- âœ” Application Shiny avancÃ©e  
- âœ” Visualisations interactives  
- âœ” Nouvelles variables (num & quali)  
- âœ” Documentation complÃ¨te  
