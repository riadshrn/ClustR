# ClustR  
### Clustering de Variables : K-means â€“ Qualitatif â€“ Deep Learning  
**Package R + Application Shiny**

---

## ğŸ“Œ PrÃ©sentation

**ClustR** est un package R dÃ©diÃ© au **clustering de variables**, permettant de regrouper des variables similaires pour :

- rÃ©duire la dimension,
- crÃ©er des variables synthÃ©tiques,
- amÃ©liorer lâ€™interprÃ©tation,
- faciliter les modÃ¨les prÃ©dictifs.

Il intÃ¨gre **trois algorithmes complÃ©mentaires** :

1. **ClustKMeansVar** â€” PCA + K-means rÃ©allocatif  
2. **ClustQualiVarclus** â€” MCA + rapport de corrÃ©lation Î·Â²  
3. **ClustDeepVar** â€” Autoencodeur + clustering dans lâ€™espace latent  

---

# ğŸš€ 1. ClustKMeansVar (K-means rÃ©allocatif)

MÃ©thode inspirÃ©e de Vigneau & Qannari (2003) :contentReference[oaicite:1]{index=1}.

## ğŸ”¹ Principe gÃ©nÃ©ral  
Les variables sont regroupÃ©es selon leur corrÃ©lation avec la **synthetic variable** (PC1) du cluster.

Pour chaque cluster \(C_g\), la synthetic variable est :

y_g = X_{C_g} * w_g


avec :

\[
w_g = \arg\max_{\|w\|=1} w^\top S_g w
\]

oÃ¹ \(S_g = X_{C_g}^\top X_{C_g}\).

## ğŸ”¹ Distance variableâ€“cluster  
\[
d(j,g) = 1 - \rho(X_j , y_g)^2
\]

La variable \(X_j\) est affectÃ©e au cluster minimisant \(d(j,g)\).

## ğŸ”¹ CritÃ¨re global optimisÃ©  
\[
Q = \frac{B}{T}, \quad T = W + B
\]

oÃ¹ :

- \(W\) = inertie intra-cluster  
- \(B\) = inertie inter-clusters  

ğŸ’¡ **Plus Q est proche de 1, meilleure est la partition.**

## ğŸ”¹ Algorithme complet  
1. Standardiser les variables  
2. Initialiser une partition  
3. Calculer PC1 de chaque cluster  
4. RÃ©affecter chaque variable au cluster optimisant \(d(j,g)\)  
5. Mettre Ã  jour Q  
6. RÃ©pÃ©ter jusquâ€™Ã  convergence  

---

# ğŸš€ 2. ClustQualiVarclus (Clustering qualitatif par MCA + Î·Â²)

MÃ©thode dÃ©diÃ©e aux variables catÃ©gorielles basÃ©e sur lâ€™ACM :contentReference[oaicite:2]{index=2}.

## ğŸ”¹ Ã‰tape 1 â€” Encodage disjonctif complet  
Chaque variable catÃ©gorielle devient des indicatrices (one-hot) :

\[
X \to Z \in \{0,1\}^{n \times m}
\]

## ğŸ”¹ Ã‰tape 2 â€” MCA par cluster  
On rÃ©alise une analyse des correspondances multiples sur les modalitÃ©s du cluster.

Lâ€™axe principal obtenu est \(Y_g\).

## ğŸ”¹ Ã‰tape 3 â€” Rapport de corrÃ©lation Î·Â²  
Pour une variable \(V\) et un axe factoriel \(Y_g\) :

\[
\eta^2(V, Y_g)
= \frac{\mathrm{Var}\left(\mathbb{E}[Y_g \mid V]\right)}{\mathrm{Var}(Y_g)}
\]

**Affectation :**

\[
V \in C_g \quad \Longleftrightarrow \quad g = \arg\max_{h} \eta^2(V, Y_h)
\]

## ğŸ”¹ Algorithme complet  
1. Partition initiale des variables  
2. MCA pour chaque cluster  
3. Calcul de \(\eta^2(V,Y_g)\) pour chaque variable  
4. RÃ©affectation selon lâ€™Î·Â² maximal  
5. RÃ©pÃ©ter jusquâ€™Ã  convergence  

## ğŸ”¹ Atouts  
- IdÃ©al pour variables nominales / ordinales  
- BasÃ© sur la gÃ©omÃ©trie du Ï‡Â²  
- InterprÃ©tation claire via lâ€™ACM  

---

# ğŸš€ 3. ClustDeepVar (Autoencodeur + clustering latent)

Algorithme deep learning pour capturer les **relations non linÃ©aires** entre variables :contentReference[oaicite:3]{index=3}.

## ğŸ”¹ Ã‰tape 1 â€” Standardisation  
\[
X_{\text{std}} = \frac{X - \mu}{\sigma}
\]

## ğŸ”¹ Ã‰tape 2 â€” Transposition  
Chaque variable devient une â€œobservationâ€ :

\[
X^\top \in \mathbb{R}^{p \times n}
\]

## ğŸ”¹ Ã‰tape 3 â€” Encodeur (embeddings)  
\[
Z = f_{\text{enc}}(X^\top), \qquad Z \in \mathbb{R}^{p \times d}
\]

Chaque variable est reprÃ©sentÃ©e par un vecteur latent \(z_j \in \mathbb{R}^d\).

## ğŸ”¹ Ã‰tape 4 â€” Reconstruction  
\[
\hat{X}^\top = f_{\text{dec}}(Z)
\]

## ğŸ”¹ Projection de variables illustratives  
\[
z_{\text{illu}} =
\frac{\sum_j \rho(x_j, v) z_j}{\sum_j \rho(x_j, v)}
\]


## ğŸ”¹ Ã‰tape 5 â€” Clustering des embeddings  
\[
C = \text{k-means}(Z, k)
\]

## ğŸ”¹ Soft clustering  
\[
p_{jk} = 
\frac{
\exp(-\|z_j - \mu_k\|^2)
}{
\sum_{\ell} \exp(-\|z_j - \mu_\ell\|^2)
}
\]

## ğŸ”¹ Projection de variables illustratives  

\[
z_{\text{illu}} =
\frac{\sum_j \rho(x_j, v) z_j}{\sum_j \rho(x_j, v)}
\]

---

# ğŸ“Š Fonctions principales de lâ€™application Shiny

### âœ” Chargement de donnÃ©es  
- Jeux intÃ©grÃ©s  
- Upload CSV / TSV / XLSX  
- DÃ©tection automatique des types et NA  

### âœ” SÃ©lection des variables  
- Actives vs illustratives  
- DÃ©tection automatique des variables redondantes  
- Matrice de corrÃ©lation  

### âœ” Choix de lâ€™algorithme  
- DÃ©tection automatique selon le type de donnÃ©es  
- RÃ©glages :  
  - `n_clusters`  
  - `latent_dim`, `epochs`, `dropout` (deep)  

### âœ” Visualisations  
- PCA (KMeans)  
- MCA (Quali)  
- Embeddings 2D/3D (Deep)  
- Heatmaps, distances inter-clusters  
- Î·Â², inerties, silhouette  

### âœ” Nouvelles variables  
- NumÃ©riques : somme / moyenne / ratio / produit / max/min  
- Qualitatives : combinaison, ifelse factor, quantiles  
- Projection dans PCA, MCA ou latent space  
- Soft membership complet  

---

# ğŸ‘¥ Auteurs

- **Riad SAHRANE**  
- **Aya MECHERI**  
- **Thibaud LECOMTE**  
Encadrant : **Ricco Rakotomalala**

---

# ğŸ Statut du projet

- âœ” Package R complet  
- âœ” Application Shiny avancÃ©e  
- âœ” Visualisations interactives  
- âœ” Nouvelles variables (num & quali)  
- âœ” Documentation complÃ¨te  

